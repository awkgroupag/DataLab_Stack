{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Controlboard for different Data Analytics-Stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Vanilla-Jupyter-Datascience-Notebook](#Vanilla-Jupyter-Datascience-Notebook)\n",
    "2. [Elastic Stack (formerly ELK-Stack)](#Elastic-Stack-(formerly-ELK-Stack))\n",
    "3. [Neo4j](#Neo4j)\n",
    "4. [Manipulate your Docker environment](#Manipulate-your-Docker-environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Vanilla Jupyter Datascience-Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Your \"standard\" [Jupyter Notebook for Datascience](https://github.com/jupyter/docker-stacks/tree/master/datascience-notebook), all packages updated. Missing an important library? Then let the AWK team know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some variables first\n",
    "\n",
    "Specify the Windows directory you want to mount. All **data in the JupyterLab's \"work\" directory will thus survive the destruction of the container**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = r\"C:\\Users\\kat\\Documents\\GitHub\\example-repo\";\n",
    "\n",
    "# Need to convert Windows path for Docker (linux-based)\n",
    "work_dir = work_dir.replace(\"\\\\\", \"/\").replace(\":\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker image version/\"tag\" of the Jupyter Datascience-Notebook you want to launch (see the [AWK Repo on Dockerhub](https://hub.docker.com/repository/docker/awkgroupag/datascience-notebook/tags) for the latest tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_version = \"e56df3a\"\n",
    "\n",
    "# You might want to change the Docker image used or the port Jupyter runs under (e.g. if you want to run several Jupyters)\n",
    "notebook = \"awkgroupag/datascience-notebook\"\n",
    "port = 8888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the container (be sure to run the cells above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker container run -d -p $port:8888 \\\n",
    "    -e JUPYTER_ENABLE_LAB=yes \\\n",
    "    -v //$work_dir:/home/jovyan/work \\\n",
    "    --name jupyter \\\n",
    "    --network=datalab-network \\\n",
    "    $notebook:$notebook_version \n",
    "! echo && echo Waiting for 5 seconds for the container to spin up && echo\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "import time\n",
    "time.sleep(5)\n",
    "log = ! sudo docker logs jupyter\n",
    "url = 'http://127.0.0.1:8888'\n",
    "for line in log:\n",
    "    if url in line:\n",
    "        break\n",
    "else:\n",
    "    print(log)\n",
    "    raise RuntimeError('Did not find URL in the log above')\n",
    "url = url[:-4] + str(port) + line.split(url, 1)[1]\n",
    "md(f\"**Your Jupyterlab URL is** {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up\n",
    "Stop the Vanilla Jupyter Notebook. Container won't be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker stop jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker rm jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Elastic Stack (formerly ELK-Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Elasticsearch, Kibana, Beats, and Logstash. Take data from any source, in any format, then search, analyze, and visualize it in real time.\n",
    "\n",
    "* **Elasticsearch** is a distributed, RESTful search and analytics engine. As the heart of the Elastic Stack, it centrally stores your data for lightning fast search, fineâ€‘tuned relevancy, and powerful analytics that scale with ease.\n",
    "* **Kibana** lets you visualize your Elasticsearch data and navigate the Elastic Stack so you can do anything from tracking query load to understanding the way requests flow through your apps.\n",
    "* **Logstash** is a server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite \"stash.\"\n",
    "* **Beats** is the platform for single-purpose data shippers. They send data from hundreds or thousands of machines and systems to Logstash.\n",
    "\n",
    "Note that Beats (e.g. Metricbeat or Systembeat) are not included in this stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connections once the stack has been started\n",
    "* Direct Kibana browser access: [http://localhost:5601](http://localhost:5601)\n",
    "* Elasticsearch access for Windows: [http://localhost:9200](http://localhost:9200)\n",
    "* Access Elasticsearch from **within** a Jupyter container: [http://elasticsearch:9200](http://elasticsearch:9200)\n",
    "* Logstash access from **within** a Jupyter container: [http://logstash:9600](http://elasticsearch:9600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a volume to persist all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume create --name=elasticsearch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the stack\n",
    "Once pull has completed and containers are running, startup might take 1-2 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./elk/docker-compose.yml\" -p \"elk\" up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop and remove the stack (Elasticsearch and Kibana data will be retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./elk/docker-compose.yml\" -p \"elk\" down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all Elasticsearch and Kibana data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume rm elasticsearch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (under construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Manipulate your Docker environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all running and stopped Docker containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all Docker images including their filesizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all volumes (=data volumes if you choose to not mount a Windows directory, for example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In desperate need to figure out what's eating up your disk space? This command shows where Docker is using disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker system df -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate a container\n",
    "Set a container name (or CONTAINER ID) first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"jupyter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker stop $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the running container's logs saved to the Python variable `logoutput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logoutput = ! sudo docker logs $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart an existing (currently stopped) container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker start $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the container completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker rm $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up and freeing disk space\n",
    "Remove an image (give either it's name or IMAGE ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"test\"\n",
    "! sudo docker image rm $image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all stopped containers at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker container prune --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove a volume (=data volume, thus potentially deleting your data!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = \"test\"\n",
    "! sudo docker volume rm $volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Danger zone**: remove all stopped containers, and all images and all volumes that are currently not associated/mounted with a **running container**. Type the following manually:\n",
    "* Delete all stopped containers, all \"dangling\" images, the build cache, any unattached network: ```! sudo docker system prune --force```\n",
    "* To also delete all currently unused images: ```! sudo docker system prune --all --force```\n",
    "* To also delete all currently unused volumes (potentially deleting your data!): ```! sudo docker system prune --volumes --force```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
