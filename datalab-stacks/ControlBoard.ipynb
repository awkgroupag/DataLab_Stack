{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlboard for Data Analytics-Stacks\n",
    "## Table of Contents\n",
    "* [Jupyter-Datascience-Notebook](#Jupyter-Datascience-Notebook)    \n",
    "* [Very helpful: Manipulate your Docker environment](#Manipulate-your-Docker-environment)\n",
    "\n",
    "Available stacks to plug into Jupyter:\n",
    "* [Elastic Stack (formerly ELK-Stack)](#Elastic-Stack-(formerly-ELK-Stack))\n",
    "* [PostgreSQL Database, using SQLAlchemy](#PostgreSQL-Database-using-SQLAlchemy)\n",
    "    - [Manage the Stack](#Manage-the-Stack)\n",
    "    - [Connect to Postgres (or any other database!)](#Connect-to-Postgres-(or-any-other-DB))\n",
    "    - [Read data from the DB into a Pandas Dataframe](#Read-data-into-a-Pandas-Dataframe)\n",
    "    - [Create an entity diagram to understand the DB schema](#Create-an-entity-diagram-for-the-database)\n",
    "* [MySQL Database, using SQLAlchemy](#MySQL)\n",
    "* [Neo4j](#Neo4j)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Jupyter Datascience-Notebook\n",
    "#### Summary\n",
    "\n",
    "Your \"standard\" [Jupyter Notebook for Datascience](https://github.com/jupyter/docker-stacks/tree/master/datascience-notebook) plus some additional libraries and the Jupyterlab extensions\n",
    "* [jupyterlab-git: git and GitHub integration](https://github.com/jupyterlab/jupyterlab-git)\n",
    "* [jupyterlab-lsp: Code completion, function definition look-up and more](https://github.com/krassowski/jupyterlab-lsp)\n",
    "* [Code debugger](https://github.com/jupyterlab/debugger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some variables first\n",
    "\n",
    "Specify **your own** local Windows directory that want to have available in Jupyter. All **data in the JupyterLab's \"work\" directory will thus survive the destruction of the container**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = r\"C:\\Users\\kat\\Documents\\GitHub\\example-repo\";\n",
    "\n",
    "# Need to convert Windows path for Docker (linux-based)\n",
    "work_dir = work_dir.replace(\"\\\\\", \"/\").replace(\":\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker image version/\"tag\" of the Jupyter Datascience-Notebook you want to launch. See the [AWK Repo on Dockerhub](https://hub.docker.com/repository/docker/awkgroupag/datascience-notebook/tags) for the latest tag (do NOT use the tag `latest`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_version = \"c7b1c1a\"\n",
    "\n",
    "# If you want to run several Jupyters in parallel, set a different name and port for each\n",
    "port = 8888\n",
    "container_name = 'jupyter'\n",
    "\n",
    "# You might want to change the Docker Hub image used\n",
    "notebook = \"awkgroupag/datascience-notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the container (be sure to run the cells above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker container run -d -p $port:8888 \\\n",
    "    -e JUPYTER_ENABLE_LAB=yes \\\n",
    "    -v \"//$work_dir:/home/jovyan/work\" \\\n",
    "    --name $container_name \\\n",
    "    --network=datalab-network \\\n",
    "    $notebook:$notebook_version \n",
    "! echo && echo Waiting for 5 seconds for the container to spin up && echo\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "import time\n",
    "time.sleep(5)\n",
    "log = ! sudo docker logs $container_name\n",
    "url = 'http://127.0.0.1:8888'\n",
    "for line in log:\n",
    "    if url in line:\n",
    "        break\n",
    "else:\n",
    "    print(log)\n",
    "    raise RuntimeError('Did not find URL in the log above')\n",
    "url = url[:-4] + str(port) + line.split(url, 1)[1]\n",
    "md(f\"**Your Jupyterlab URL is** {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopping and cleaning up\n",
    "Stop the Vanilla Jupyter Notebook. Container won't be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker stop $container_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker rm $container_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to save your entire computational context if you installed additional packages\n",
    "You might change your Docker container by installing new **PIP** Python packages e.g. with `pip install <package name>`. This change will be lost with the container. To quickly save your entire pip environment, including all packages, copy-paste the following into your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze > /home/jovyan/work/pip-environment.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load your environment again from scratch, e.g. if you re-created your Docker container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r /home/jovyan/work/pip-environment.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you installed additional Python packages with **Anaconda**, `conda install <package name>`, here's how to save the entire conda environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda env export -n base > /home/jovyan/work/anaconda-environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To re-install all Anaconda packages from this file, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda env update --name base --file /home/jovyan/work/anaconda-environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Elastic Stack (formerly ELK-Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Elasticsearch, Kibana, Beats, and Logstash. Take data from any source, in any format, then search, analyze, and visualize it in real time.\n",
    "\n",
    "* **Elasticsearch** is a distributed, RESTful search and analytics engine. As the heart of the Elastic Stack, it centrally stores your data for lightning fast search, fineâ€‘tuned relevancy, and powerful analytics that scale with ease.\n",
    "* **Kibana** lets you visualize your Elasticsearch data and navigate the Elastic Stack so you can do anything from tracking query load to understanding the way requests flow through your apps.\n",
    "* **Logstash** is a server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite \"stash.\"\n",
    "* **Beats** is the platform for single-purpose data shippers. They send data from hundreds or thousands of machines and systems to Logstash.\n",
    "\n",
    "Note that Beats (e.g. Metricbeat or Systembeat) are not included in this stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connections once the stack has been started\n",
    "* Direct Kibana browser access: [http://localhost:5601](http://localhost:5601)\n",
    "* Elasticsearch access for Windows: [http://localhost:9200](http://localhost:9200)\n",
    "* Access Elasticsearch from **within** a Jupyter container: [http://elasticsearch:9200](http://elasticsearch:9200)\n",
    "* Logstash access from **within** a Jupyter container: [http://logstash:9600](http://elasticsearch:9600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a volume to persist all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume create --name=elasticsearch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start the stack\n",
    "Once pull has completed and containers are running, startup might take 1-2 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./elk/docker-compose.yml\" -p \"elk\" up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop and remove the stack (Elasticsearch and Kibana data will be retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./elk/docker-compose.yml\" -p \"elk\" down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all Elasticsearch and Kibana data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume rm elasticsearch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## PostgreSQL Database using SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PostgreSQL](https://en.wikipedia.org/wiki/PostgreSQL) is a powerful, open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\n",
    "* [SQLAlchemy](https://www.sqlalchemy.org/) is a GREAT Python wrapper to talk to almost any database.\n",
    "\n",
    "\n",
    "Check out the [Database getting started Jupyter notebook](database_getting_started.ipynb) for code snippets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage the Stack\n",
    "Create a volume to persist all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume create postgres_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./postgres/docker-compose.yml\" -p \"postgres\" up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop and remove the stack (database will be retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./postgres/docker-compose.yml\" -p \"postgres\" down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the actual database and thus all Postgre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume rm postgres_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# MySQL\n",
    "* [MySQL](https://www.mysql.com) is another popular database.\n",
    "* [SQLAlchemy](https://www.sqlalchemy.org/) is a GREAT Python wrapper to talk to almost any database.\n",
    "\n",
    "Check out the [Database getting started Jupyter notebook](database_getting_started.ipynb) for code snippets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage the stack\n",
    "Create a volume to persist all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume create mysql_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./mysql/docker-compose.yml\" -p \"mysql\" up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop and remove the stack (database will be retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker-compose -f \"./mysql/docker-compose.yml\" -p \"mysql\" down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the actual database and thus all MySQL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume rm mysql_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (under construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Manipulate your Docker environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all running and stopped Docker containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all Docker images including their filesizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all volumes (=data volumes if you choose to not mount a Windows directory, for example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker volume ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In desperate need to figure out what's eating up your disk space? This command shows where Docker is using disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker system df -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate a container\n",
    "Set a container name (or CONTAINER ID) first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"jupyter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker stop $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the running container's logs saved to the Python variable `logoutput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logoutput = ! sudo docker logs $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart an existing (currently stopped) container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker start $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the container completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker rm $container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up and freeing disk space\n",
    "Remove an image (give either it's name or IMAGE ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"test\"\n",
    "! sudo docker image rm $image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all stopped containers at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo docker container prune --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove a volume (=data volume, thus potentially deleting your data!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = \"test\"\n",
    "! sudo docker volume rm $volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Danger zone**: remove all stopped containers, and all images and all volumes that are currently not associated/mounted with a **running container**. Type the following manually:\n",
    "* Delete all stopped containers, all \"dangling\" images, the build cache, any unattached network: ```! sudo docker system prune --force```\n",
    "* To also delete all currently unused images: ```! sudo docker system prune --all --force```\n",
    "* To also delete all currently unused volumes (potentially deleting your data!): ```! sudo docker system prune --volumes --force```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
